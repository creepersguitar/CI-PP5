{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Heretage Housing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Introduction\n",
        "\"\"\"\n",
        "This notebook aims to help maximize the sale prices of four inherited properties in Ames, Iowa by analyzing house features and building a machine learning model to predict house sale prices.\n",
        "We will explore several hypotheses and validate them through data analysis and visualizations.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Write your notebook objective here, for example, \"Fetch data from Kaggle and save as raw data\", or \"engineer features for modelling\"\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Write here which data or information you need to run the notebook \n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Write here which files, code or artefacts you generate by the end of the notebook \n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* In case you have any additional comments that don't fit in the previous bullets, please state them here. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Section 1 loading imports and files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This section is just to simply load all imports and files needed in order to rurn the rest of the notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Data Loading and Preprocessing\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('AmesHousing.csv')  # Update with the correct path to the dataset\n",
        "\n",
        "# Check for missing values and basic data info\n",
        "print(df.info())\n",
        "print(df.describe())\n",
        "\n",
        "# Fill missing values or drop columns if necessary\n",
        "df.fillna(df.median(), inplace=True)\n",
        "\n",
        "# Encode categorical features\n",
        "le = LabelEncoder()\n",
        "df['Neighborhood'] = le.fit_transform(df['Neighborhood'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Section 2 (EDA analysis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This section is about the Analysis and plotting of the dataset given to me when i first forked the template at the start of this project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Exploratory Data Analysis (EDA)\n",
        "\n",
        "# Correlation Heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()\n",
        "\n",
        "# Scatter plot: Hypothesis 1 - Total Square Footage vs Sale Price\n",
        "df['TotalSF'] = df['1stFlrSF'] + df['2ndFlrSF'] + df['TotalBsmtSF']\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(df['TotalSF'], df['SalePrice'], alpha=0.5)\n",
        "plt.title('Total Square Footage vs Sale Price')\n",
        "plt.xlabel('Total Square Footage')\n",
        "plt.ylabel('Sale Price')\n",
        "plt.show()\n",
        "\n",
        "# Box plot: Hypothesis 2 - Neighborhood vs Sale Price\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.boxplot(x='Neighborhood', y='SalePrice', data=df)\n",
        "plt.xticks(rotation=90)\n",
        "plt.title('Neighborhood vs Sale Price')\n",
        "plt.show()\n",
        "\n",
        "# Scatter plot: Hypothesis 3 - Overall Quality vs Sale Price\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(x='OverallQual', y='SalePrice', data=df)\n",
        "plt.title('Overall Quality vs Sale Price')\n",
        "plt.show()\n",
        "\n",
        "# Scatter plot: Hypothesis 4 - Year Built vs Sale Price\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(x='YearBuilt', y='SalePrice', data=df)\n",
        "plt.title('Year Built vs Sale Price')\n",
        "plt.show()\n",
        "\n",
        "# Box plot: Hypothesis 5 - GarageArea vs Sale Price\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(x='GarageArea', y='SalePrice', data=df)\n",
        "plt.title('Garage Area vs Sale Price')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Section 4 Machine learning model development**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This section is all about the predictions and evaluations from different models in the dataset given such as:\n",
        "- Linear regression model\n",
        "- Random Forest Model\n",
        "    - Hyperperameter tuning for the RFM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Machine Learning Model Development\n",
        "\n",
        "# Split the dataset into features (X) and target (y)\n",
        "X = df[['TotalSF', 'OverallQual', 'GarageArea', 'YearBuilt', 'Neighborhood']]\n",
        "y = df['SalePrice']\n",
        "\n",
        "# Split into training and testing datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Linear Regression Model\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions and evaluation\n",
        "y_pred_lr = lr_model.predict(X_test)\n",
        "print(f'Linear Regression R²: {r2_score(y_test, y_pred_lr)}')\n",
        "print(f'Linear Regression RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_lr))}')\n",
        "\n",
        "# Random Forest Model\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions and evaluation\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "print(f'Random Forest R²: {r2_score(y_test, y_pred_rf)}')\n",
        "print(f'Random Forest RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_rf))}')\n",
        "\n",
        "# Hyperparameter tuning with Grid Search (for Random Forest)\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20, 30]\n",
        "}\n",
        "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "grid_search.fit(X_train, y_train)\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the best Random Forest Model\n",
        "y_pred_best_rf = best_rf_model.predict(X_test)\n",
        "print(f'Best Random Forest R²: {r2_score(y_test, y_pred_best_rf)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Section 5 Model Evaluation and results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Residual plot\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(y_test, y_test - y_pred_best_rf, alpha=0.5)\n",
        "plt.title('Residuals Plot')\n",
        "plt.xlabel('Actual Sale Price')\n",
        "plt.ylabel('Residuals')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Conclusion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Larger homes tend to have higher sale prices.\n",
        "- Location plays a significant role in determining house prices.\n",
        "- Higher quality homes and newer homes fetch higher prices.\n",
        "- Additional features such as garages also increase house prices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# 7. Credits and Acknowledgements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Dataset from Ames Housing Dataset.\n",
        "- Inspiration from Machine Learning and Data Analysis walkthrough projects\n",
        "- My mentor precious ijege for his guidance in this project\n",
        "- My fellow peers such as Beth Cottel for checking in with me when times were tuff during this development (and for keeping me smiling aswell as motivated)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
