{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Heretage Housing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Introduction\n",
        "\"\"\"\n",
        "This notebook aims to help maximize the sale prices of four inherited properties in Ames, Iowa by analyzing house features and building a machine learning model to predict house sale prices.\n",
        "We will explore several hypotheses and validate them through data analysis and visualizations.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* The objective of this notebook is to fetch, clean, and analyze housing data to predict house sale prices using machine learning models. This includes performing Exploratory Data Analysis (EDA), building a predictive model, tuning it for accuracy, and evaluating the results.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* The input data is from the 'Ames Housing Dataset', a CSV file. The notebook requires the data to have features like total square footage, year built, neighborhood information, garage area, and sale price, among others. \n",
        "\n",
        "## Outputs\n",
        "\n",
        "* The outputs will include exploratory data visualizations, trained machine learning models, and their performance metrics. The final model will be able to predict sale prices based on house features. Artifacts generated include the best-tuned Random Forest model and its performance report.\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* In case you have any additional comments that don't fit in the previous bullets, please state them here. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Section 1 loading imports and files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This section is just to simply load all imports and files needed in order to rurn the rest of the notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial DataFrame preview:\n",
            "        Variable                                            Meaning  \\\n",
            "0      1stFlrSF                            First Floor square feet   \n",
            "1      2ndFlrSF                           Second-floor square feet   \n",
            "2  BedroomAbvGr  Bedrooms above grade (does NOT include basemen...   \n",
            "3  BsmtExposure            Refers to walkout or garden level walls   \n",
            "4  BsmtFinType1                   Rating of basement finished area   \n",
            "\n",
            "                                               Units  \n",
            "0                                         334 - 4692  \n",
            "1                                           0 - 2065  \n",
            "2                                              0 - 8  \n",
            "3  Gd: Good Exposure; Av: Average Exposure; Mn: M...  \n",
            "4  GLQ: Good Living Quarters; ALQ: Average Living...  \n",
            "Initial DataFrame columns: Index(['Variable', 'Meaning', 'Units'], dtype='object')\n",
            "Reshaped DataFrame preview:\n",
            " Variable    1stFlrSF  2ndFlrSF BedroomAbvGr  \\\n",
            "0         334 - 4692       NaN          NaN   \n",
            "1                NaN  0 - 2065          NaN   \n",
            "2                NaN       NaN        0 - 8   \n",
            "3                NaN       NaN          NaN   \n",
            "4                NaN       NaN          NaN   \n",
            "\n",
            "Variable                                       BsmtExposure BsmtFinSF1  \\\n",
            "0                                                       NaN        NaN   \n",
            "1                                                       NaN        NaN   \n",
            "2                                                       NaN        NaN   \n",
            "3         Gd: Good Exposure; Av: Average Exposure; Mn: M...        NaN   \n",
            "4                                                       NaN        NaN   \n",
            "\n",
            "Variable                                       BsmtFinType1 BsmtUnfSF  \\\n",
            "0                                                       NaN       NaN   \n",
            "1                                                       NaN       NaN   \n",
            "2                                                       NaN       NaN   \n",
            "3                                                       NaN       NaN   \n",
            "4         GLQ: Good Living Quarters; ALQ: Average Living...       NaN   \n",
            "\n",
            "Variable EnclosedPorch GarageArea GarageFinish  ... LotFrontage MasVnrArea  \\\n",
            "0                  NaN        NaN          NaN  ...         NaN        NaN   \n",
            "1                  NaN        NaN          NaN  ...         NaN        NaN   \n",
            "2                  NaN        NaN          NaN  ...         NaN        NaN   \n",
            "3                  NaN        NaN          NaN  ...         NaN        NaN   \n",
            "4                  NaN        NaN          NaN  ...         NaN        NaN   \n",
            "\n",
            "Variable OpenPorchSF OverallCond OverallQual SalePrice TotalBsmtSF WoodDeckSF  \\\n",
            "0                NaN         NaN         NaN       NaN         NaN        NaN   \n",
            "1                NaN         NaN         NaN       NaN         NaN        NaN   \n",
            "2                NaN         NaN         NaN       NaN         NaN        NaN   \n",
            "3                NaN         NaN         NaN       NaN         NaN        NaN   \n",
            "4                NaN         NaN         NaN       NaN         NaN        NaN   \n",
            "\n",
            "Variable YearBuilt YearRemodAdd  \n",
            "0              NaN          NaN  \n",
            "1              NaN          NaN  \n",
            "2              NaN          NaN  \n",
            "3              NaN          NaN  \n",
            "4              NaN          NaN  \n",
            "\n",
            "[5 rows x 24 columns]\n",
            "Columns after pivoting: Index(['1stFlrSF', '2ndFlrSF', 'BedroomAbvGr', 'BsmtExposure', 'BsmtFinSF1',\n",
            "       'BsmtFinType1', 'BsmtUnfSF', 'EnclosedPorch', 'GarageArea',\n",
            "       'GarageFinish', 'GarageYrBlt', 'GrLivArea', 'KitchenQual', 'LotArea',\n",
            "       'LotFrontage', 'MasVnrArea', 'OpenPorchSF', 'OverallCond',\n",
            "       'OverallQual', 'SalePrice', 'TotalBsmtSF', 'WoodDeckSF', 'YearBuilt',\n",
            "       'YearRemodAdd'],\n",
            "      dtype='object', name='Variable')\n",
            "Unique values in OverallQual before encoding: [nan\n",
            " '10: Very Excellent; 9: Excellent; 8: Very Good; 7: Good; 6: Above Average; 5: Average; 4: Below Average; 3: Fair; 2: Poor; 1: Very Poor']\n",
            "Unique values in YearBuilt before cleaning: [nan '1872 - 2010']\n",
            "Unique values in YearBuilt after cleaning: [  nan 1872.]\n",
            "Shape of X before NaN handling: (24, 4)\n",
            "Shape of y before NaN handling: (24,)\n",
            "NaN values in X: Variable\n",
            "TotalSF        24\n",
            "OverallQual     0\n",
            "GarageArea     23\n",
            "YearBuilt      23\n",
            "dtype: int64\n",
            "NaN values in y: 23\n",
            "Shape of X after NaN handling: (0, 4)\n",
            "Shape of y after NaN handling: (0,)\n",
            "No samples left for training and testing. Please check your data handling steps.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1628/3802410212.py:40: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  df_pivot.fillna(df_pivot.median(), inplace=True)\n"
          ]
        }
      ],
      "source": [
        "# 1. Imports and Data Loading\n",
        "import os\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Path to the CSV file inside the assets folder\n",
        "file_path = '../assets/AmesHousing.csv'\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Ensure no leading or trailing spaces in column names\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Check the structure of the DataFrame\n",
        "print(\"Initial DataFrame preview:\\n\", df.head())\n",
        "print(\"Initial DataFrame columns:\", df.columns)\n",
        "\n",
        "# Reshape the DataFrame: Pivot the variable names into columns\n",
        "# Assuming the DataFrame has 'Variable' and 'Value' columns\n",
        "df_pivot = df.pivot(index=None, columns='Variable', values='Units')\n",
        "\n",
        "# Reset index if needed\n",
        "df_pivot.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Display the reshaped DataFrame for verification\n",
        "print(\"Reshaped DataFrame preview:\\n\", df_pivot.head())\n",
        "print(\"Columns after pivoting:\", df_pivot.columns)\n",
        "\n",
        "# Fill missing values with the median\n",
        "df_pivot.fillna(df_pivot.median(), inplace=True)\n",
        "\n",
        "# Convert categorical features to numeric\n",
        "# If 'OverallQual' or other categorical columns have not been converted, do so\n",
        "if 'OverallQual' in df_pivot.columns and df_pivot['OverallQual'].dtype == 'object':\n",
        "    print(\"Unique values in OverallQual before encoding:\", df_pivot['OverallQual'].unique())\n",
        "    le = LabelEncoder()\n",
        "    df_pivot['OverallQual'] = le.fit_transform(df_pivot['OverallQual'])\n",
        "\n",
        "# Check the YearBuilt column for issues\n",
        "if 'YearBuilt' in df_pivot.columns:\n",
        "    print(\"Unique values in YearBuilt before cleaning:\", df_pivot['YearBuilt'].unique())\n",
        "    # Clean the YearBuilt column\n",
        "    df_pivot['YearBuilt'] = pd.to_numeric(df_pivot['YearBuilt'].str.split(' - ').str[0], errors='coerce')\n",
        "    print(\"Unique values in YearBuilt after cleaning:\", df_pivot['YearBuilt'].unique())\n",
        "\n",
        "# Add new feature for total square footage if the relevant columns exist\n",
        "required_columns = ['1stFlrSF', '2ndFlrSF', 'TotalBsmtSF']\n",
        "if all(col in df_pivot.columns for col in required_columns):\n",
        "    df_pivot['TotalSF'] = df_pivot['1stFlrSF'] + df_pivot['2ndFlrSF'] + df_pivot['TotalBsmtSF']\n",
        "else:\n",
        "    print(\"One or more required columns are missing for TotalSF calculation.\")\n",
        "\n",
        "# Specify features and target variable\n",
        "X = df_pivot[['TotalSF', 'OverallQual', 'GarageArea', 'YearBuilt']]\n",
        "y = df_pivot['SalePrice']\n",
        "\n",
        "# Check the shapes of X and y before proceeding\n",
        "print(\"Shape of X before NaN handling:\", X.shape)\n",
        "print(\"Shape of y before NaN handling:\", y.shape)\n",
        "\n",
        "# Check for NaN values in features and target variable\n",
        "print(\"NaN values in X:\", X.isnull().sum())\n",
        "print(\"NaN values in y:\", y.isnull().sum())\n",
        "\n",
        "# Handle NaN values: Option 1: Drop rows with NaN values\n",
        "X = X.dropna()\n",
        "y = y[X.index]  # Align y with X after dropping\n",
        "\n",
        "# Alternatively, you can fill NaN values instead of dropping\n",
        "# X.fillna(X.median(), inplace=True)\n",
        "\n",
        "# Check the shape after dropping NaNs\n",
        "print(\"Shape of X after NaN handling:\", X.shape)\n",
        "print(\"Shape of y after NaN handling:\", y.shape)\n",
        "\n",
        "# Check if there are any samples left to split\n",
        "if X.shape[0] == 0 or y.shape[0] == 0:\n",
        "    print(\"No samples left for training and testing. Please check your data handling steps.\")\n",
        "else:\n",
        "    # Split into training and testing datasets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train the Random Forest model\n",
        "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "    rf_model.fit(X_train, y_train)\n",
        "\n",
        "    # Title of the dashboard\n",
        "    st.title(\"Heritage Housing Price Prediction Dashboard\")\n",
        "\n",
        "    # Write introduction text\n",
        "    st.write(\"This dashboard helps predict house prices in Ames, Iowa using Exploratory Data Analysis and machine learning models.\")\n",
        "\n",
        "    # Display the first few rows of the dataset for reference\n",
        "    st.write(\"### Ames Housing Dataset Preview:\")\n",
        "    st.dataframe(df_pivot.head())\n",
        "\n",
        "    # Display the shape of the dataset (rows and columns)\n",
        "    st.write(f\"Number of Rows: {df_pivot.shape[0]}, Number of Columns: {df_pivot.shape[1]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Section 2 (EDA analysis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This section is about the Analysis and plotting of the dataset given to me when i first forked the template at the start of this project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Exploratory Data Analysis (EDA)\n",
        "st.subheader('Exploratory Data Analysis')\n",
        "\n",
        "# Display the shape of the DataFrame\n",
        "st.write(f\"DataFrame Shape: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
        "\n",
        "# Check for missing values\n",
        "missing_values = df.isnull().sum()\n",
        "st.write(\"Missing Values in Each Column:\")\n",
        "st.write(missing_values)\n",
        "\n",
        "# Check if the DataFrame is empty\n",
        "if df.empty:\n",
        "    st.write(\"The DataFrame is empty. Please check the data loading process.\")\n",
        "else:\n",
        "    # Try to select only numeric columns for correlation\n",
        "    numeric_df = df.select_dtypes(include=[np.number])\n",
        "\n",
        "    # Check if there are any numeric columns to calculate the correlation\n",
        "    if numeric_df.empty:\n",
        "        st.write(\"No numeric columns available to calculate correlation.\")\n",
        "    else:\n",
        "        # Correlation Heatmap\n",
        "        st.write(\"### Correlation Heatmap\")\n",
        "        fig, ax = plt.subplots(figsize=(10, 8))\n",
        "        sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm', fmt='.2f', ax=ax)\n",
        "        st.pyplot(fig)\n",
        "\n",
        "        # Ensure 'TotalSF' and 'SalePrice' exist in DataFrame\n",
        "        if 'TotalSF' in df.columns and 'SalePrice' in df.columns:\n",
        "            # Scatter plot for Total Square Footage vs Sale Price\n",
        "            st.write(\"### Total Square Footage vs Sale Price\")\n",
        "            fig = px.scatter(df, x='TotalSF', y='SalePrice', opacity=0.5, title='Total Square Footage vs Sale Price')\n",
        "            st.plotly_chart(fig)\n",
        "\n",
        "            # Box plot for Neighborhood vs Sale Price\n",
        "            if 'Neighborhood' in df.columns:\n",
        "                st.write(\"### Neighborhood vs Sale Price\")\n",
        "                fig = px.box(df, x='Neighborhood', y='SalePrice', title='Neighborhood vs Sale Price')\n",
        "                st.plotly_chart(fig)\n",
        "            else:\n",
        "                st.write(\"Column 'Neighborhood' not found in the dataset.\")\n",
        "\n",
        "            # Scatter plot for Overall Quality vs Sale Price\n",
        "            if 'OverallQual' in df.columns:\n",
        "                st.write(\"### Overall Quality vs Sale Price\")\n",
        "                fig = px.scatter(df, x='OverallQual', y='SalePrice', opacity=0.5, title='Overall Quality vs Sale Price')\n",
        "                st.plotly_chart(fig)\n",
        "            else:\n",
        "                st.write(\"Column 'OverallQual' not found in the dataset.\")\n",
        "\n",
        "            # Scatter plot for Year Built vs Sale Price\n",
        "            if 'YearBuilt' in df.columns:\n",
        "                st.write(\"### Year Built vs Sale Price\")\n",
        "                fig = px.scatter(df, x='YearBuilt', y='SalePrice', opacity=0.5, title='Year Built vs Sale Price')\n",
        "                st.plotly_chart(fig)\n",
        "            else:\n",
        "                st.write(\"Column 'YearBuilt' not found in the dataset.\")\n",
        "\n",
        "            # Scatter plot for Garage Area vs Sale Price\n",
        "            if 'GarageArea' in df.columns:\n",
        "                st.write(\"### Garage Area vs Sale Price\")\n",
        "                fig = px.scatter(df, x='GarageArea', y='SalePrice', opacity=0.5, title='Garage Area vs Sale Price')\n",
        "                st.plotly_chart(fig)\n",
        "            else:\n",
        "                st.write(\"Column 'GarageArea' not found in the dataset.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Section 4 Machine learning model development**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This section is all about the predictions and evaluations from different models in the dataset given such as:\n",
        "- Linear regression model\n",
        "- Random Forest Model\n",
        "    - Hyperperameter tuning for the RFM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'TotalSF'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'TotalSF'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[25], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Sidebar for user input\u001b[39;00m\n\u001b[1;32m     10\u001b[0m st\u001b[38;5;241m.\u001b[39msidebar\u001b[38;5;241m.\u001b[39mheader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput Features\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m total_sf \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39msidebar\u001b[38;5;241m.\u001b[39mslider(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal Square Footage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mint\u001b[39m(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTotalSF\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmin()), \u001b[38;5;28mint\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotalSF\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()), \u001b[38;5;28mint\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotalSF\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()))\n\u001b[1;32m     12\u001b[0m overall_qual \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39msidebar\u001b[38;5;241m.\u001b[39mslider(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOverall Quality\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mint\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOverallQual\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmin()), \u001b[38;5;28mint\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOverallQual\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()), \u001b[38;5;28mint\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOverallQual\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()))\n\u001b[1;32m     13\u001b[0m garage_area \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39msidebar\u001b[38;5;241m.\u001b[39mslider(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGarage Area\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mint\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGarageArea\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmin()), \u001b[38;5;28mint\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGarageArea\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()), \u001b[38;5;28mint\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGarageArea\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()))\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[0;31mKeyError\u001b[0m: 'TotalSF'"
          ]
        }
      ],
      "source": [
        "# 3. Machine Learning Model Development\n",
        "\n",
        "# Function to make predictions\n",
        "def predict_price(total_sf, overall_qual, garage_area, year_built):\n",
        "    input_data = pd.DataFrame([[total_sf, overall_qual, garage_area, year_built]], \n",
        "                              columns=['TotalSF', 'OverallQual', 'GarageArea', 'YearBuilt'])\n",
        "    return rf_model.predict(input_data)[0]\n",
        "\n",
        "# Sidebar for user input\n",
        "st.sidebar.header(\"Input Features\")\n",
        "total_sf = st.sidebar.slider('Total Square Footage', int(df['TotalSF'].min()), int(df['TotalSF'].max()), int(df['TotalSF'].mean()))\n",
        "overall_qual = st.sidebar.slider('Overall Quality', int(df['OverallQual'].min()), int(df['OverallQual'].max()), int(df['OverallQual'].mean()))\n",
        "garage_area = st.sidebar.slider('Garage Area', int(df['GarageArea'].min()), int(df['GarageArea'].max()), int(df['GarageArea'].mean()))\n",
        "year_built = st.sidebar.slider('Year Built', int(df['YearBuilt'].min()), int(df['YearBuilt'].max()), int(df['YearBuilt'].mean()))\n",
        "\n",
        "# Predict house price based on input\n",
        "if st.sidebar.button(\"Predict Sale Price\"):\n",
        "    price = predict_price(total_sf, overall_qual, garage_area, year_built)\n",
        "    st.write(f\"### Predicted Sale Price: ${price:,.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Section 5 Model Evaluation and results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Model Evaluation and Results\n",
        "\n",
        "# Residuals Plot\n",
        "st.subheader(\"Model Evaluation\")\n",
        "st.write(\"### Residuals Plot\")\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "fig, ax = plt.subplots(figsize=(8,6))\n",
        "plt.scatter(y_test, y_test - y_pred_rf, alpha=0.5)\n",
        "plt.title('Residuals Plot')\n",
        "plt.xlabel('Actual Sale Price')\n",
        "plt.ylabel('Residuals')\n",
        "st.pyplot(fig)\n",
        "\n",
        "# Display R² and RMSE for the model\n",
        "st.write(f\"### Random Forest R²: {r2_score(y_test, y_pred_rf):.4f}\")\n",
        "st.write(f\"### Random Forest RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_rf)):.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Conclusion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From the analysis, we found that larger homes, higher quality, and newer homes fetch higher sale prices. Features such as location (neighborhood) and garage space also impact prices significantly. The best-tuned Random Forest model provided accurate predictions, and feature importance analysis showed that house size and overall quality are key drivers of sale price."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# 7. Credits and Acknowledgements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Dataset from Ames Housing Dataset.\n",
        "- Inspiration from Machine Learning and Data Analysis walkthrough projects\n",
        "- My mentor precious ijege for his guidance in this project\n",
        "- My fellow peers such as Beth Cottel for checking in with me when times were tuff during this development (and for keeping me smiling aswell as motivated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Limitations and Next steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* One limitation of the model is that we focused on a subset of features; other factors such as market conditions or interior characteristics might also impact house prices."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
